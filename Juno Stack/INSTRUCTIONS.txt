# How to Use JunoStack â€” AI Programming Assistant Language

JunoStack is a language for building tools with AI assistance. You can route prompts to specific AI models using intuitive declarations.

---

## Core Concepts

### 1. Declare API Keys
```t
apikey ollama = "http://localhost:11434";
```

This tells JunoStack where to route `callMode(...)` requests (i.e., your Ollama server).

---

### 2. Assign Models to Modes
```t
mode coder = "qwen_4b";
```

You can use friendly model aliases â€” these will be mapped to real Ollama model names under the hood.

---

### 3. Set Mode Instructions
```t
modeInstructions["coder"] = "write code following blueprint";
```

These instructions guide how the model behaves when used.

---

### 4. Create Profiles
```t
profile production {
    coder,
    debug,
    manager
}
```

Profiles bundle modes into a named context you can reuse.  (WIP)

---

### 5. Switch Context & Call AI
```t
currentProfile = "production";
currentMode = "coder";
callMode("Create a login form with validation.");
```

---

## Supported Aliases

| Alias         | Actual Model |
|---------------|--------------|
| qwen_4b       | qwen3:4b     |
| gemma_4b      | gemma3:4b    |
| mistral       | mistral      |

---

## Testing & Running

Run a test file with:

```bash
python runner.py test_modes2.t
python runner.py test_blueprint.t
python runner.py test_coder.t
python runner.py test_debug.t
python runner.py test_manager.t
```

Edit `test_modes2.t` to try new prompts, mode setups, or model ideas.

If it breaks â€” just yell for Brandon ðŸ˜„

You've got this 