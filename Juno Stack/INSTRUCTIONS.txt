# How to Use JunoStack â€” AI Programming Assistant Language

This guide walks you through how to use JunoStack, a language designed for building and working with multiple AI models like local LLMs using Ollama.

---

## ðŸ§¾ Key Concepts

### 1. Declare Your API Server
```t
apikey ollama = "http://localhost:11434";
```

This tells JunoStack where to send model requests.

---

### 2. Assign Models to Modes
```t
mode coder = "qwen3";
```

This links a logical role to a model (used with Ollama).

---

### 3. Define Mode Instructions
```t
modeInstructions = "write code according to blueprint";
```

This is tied to the most recently declared mode.

---

### 4. Group Modes Into Profiles
```t
profile production {
    blueprint,
    coder,
    manager
}
```

Profiles are collections of modes that define a working context.

---

### 5. Switch Contexts and Call AI
```t
currentProfile = "production";
currentMode = "coder";
callMode("Build login and registration endpoints");
```

---

## ðŸš€ How to Run

In terminal:

```bash
python runner.py test_modes.t
```

JunoStack will route prompts to your local models based on the current mode and its instructions.

---

## Want to Try More?

Edit `test_modes.t` to create your own profiles, modes, and instruction flows!

If anything breaks or you get confused, text Brandon.

You've got this ðŸ’¡
